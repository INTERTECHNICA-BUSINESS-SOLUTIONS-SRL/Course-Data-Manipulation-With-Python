{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDuU6OSWXKo4"
      },
      "source": [
        "![*INTERTECHNICA - SOLON EDUCATIONAL PROGRAMS - TECHNOLOGY LINE*](https://solon.intertechnica.com/assets/IntertechnicaSolonEducationalPrograms-TechnologyLine.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeBbVwSSXKo9"
      },
      "source": [
        "# Data Manipulation with Python - Advanced Data Manipulation - Data Pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUhqqWdPXKpA"
      },
      "source": [
        "*Basic initialization of the workspace.*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install numpy\n",
        "import numpy as np\n",
        "print (\"NumPy installed at version: {}\".format(np.__version__))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJzCFKioH6UR",
        "outputId": "f926f0cc-eb52-4305-9904-f13a1263fa04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "NumPy installed at version: 1.19.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjAZRU7GXKpE",
        "outputId": "b4abda13-7d51-40aa-91ed-3ae65002117b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Pandas installed at version: 1.3.5\n"
          ]
        }
      ],
      "source": [
        "!python -m pip install pandas\n",
        "import pandas as pd\n",
        "print (\"Pandas installed at version: {}\".format(pd.__version__))\n",
        "\n",
        "#adjust pandas DataFrame display for a wider target \n",
        "pd.set_option('display.expand_frame_repr', False)\n",
        "\n",
        "# disable warnings for chained assignment\n",
        "pd.set_option('mode.chained_assignment', None)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install sklearn\n",
        "import sklearn as skl\n",
        "import sklearn.base as sklb\n",
        "import sklearn.preprocessing as sklpre\n",
        "import sklearn.pipeline as sklpipe\n",
        "import sklearn.compose as sklcompose\n",
        "\n",
        "print (\"Sklearn installed at version: {}\".format(skl.__version__))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbyxoZM02V84",
        "outputId": "f5563756-c8d4-4ab2-ef35-9bd6171f6111"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.19.5)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.1.0)\n",
            "Sklearn installed at version: 1.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "\n",
        "# supress RuntimeWarnings that are not relevant\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "iMF0sJ6rN8Fj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1 Loading Data"
      ],
      "metadata": {
        "id": "mPYkEjtYty65"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will focus on processing a dataset focused on immigration data. It contains the number of foreign born citizens in different countries, considering different genders in different years. \n",
        "\n",
        "The dataset values have been pre-processed so that the immigrant stock values have been imputed, numerical features have been scaled and the categorical values have been one-hot encoded.\n"
      ],
      "metadata": {
        "id": "jCNn1Jk-t2gz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.1 Loading and exploring data"
      ],
      "metadata": {
        "id": "PrWXFgFiugmV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First of all, loading data and basic exploration of the dataset structure is required. "
      ],
      "metadata": {
        "id": "iQYKBLNHuZ6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load data for processing\n",
        "loaded_data = pd.read_parquet(\n",
        "    \"https://github.com/INTERTECHNICA-BUSINESS-SOLUTIONS-SRL/CourseDataManipulationWithPython/raw/main/Module%204%20-%20Advanced%20Data%20Manipulation/Session%202%20-%20Advanced%20Data%20Manipulation/data/migration_dataset_extended.parquet\"\n",
        ")\n",
        "\n",
        "print(\n",
        "    \"A sample of of loaded data is \\n {}\".format(\n",
        "      loaded_data[0:10]  \n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "mQy9EwjetX3W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "488828fc-d74f-47f1-a090-2f3d5d08eaad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A sample of of loaded data is \n",
            "      Year COU_ORIG Origin Country Gender COU_DEST Destination Country  Immigrant Stock  Origin Country Population  Destination Country Population\n",
            "0  2000.0      AFG    Afghanistan    MEN      AUS           Australia           6500.0                 20779957.0                      19153000.0\n",
            "1  2001.0      AFG    Afghanistan    MEN      AUS           Australia           7410.0                 21606992.0                      19413000.0\n",
            "2  2002.0      AFG    Afghanistan    MEN      AUS           Australia           8710.0                 22600774.0                      19651400.0\n",
            "3  2003.0      AFG    Afghanistan    MEN      AUS           Australia           9260.0                 23680871.0                      19895400.0\n",
            "4  2004.0      AFG    Afghanistan    MEN      AUS           Australia           9810.0                 24726689.0                      20127400.0\n",
            "5  2005.0      AFG    Afghanistan    MEN      AUS           Australia          10600.0                 25654274.0                      20394800.0\n",
            "6  2006.0      AFG    Afghanistan    MEN      AUS           Australia          12170.0                 26433058.0                      20697900.0\n",
            "7  2007.0      AFG    Afghanistan    MEN      AUS           Australia          13280.0                 27100542.0                      20827600.0\n",
            "8  2008.0      AFG    Afghanistan    MEN      AUS           Australia          14230.0                 27722281.0                      21249200.0\n",
            "9  2009.0      AFG    Afghanistan    MEN      AUS           Australia          15360.0                 28394806.0                      21691700.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can observe that the dataset has several features:\n",
        "\n",
        "*  **Year** - the year of observation;\n",
        "*  **COU_ORIG** - the ISO3 code for the country of origin;\n",
        "*  **Origin Country** - the name of the country of origin (country of birth/nationality);\n",
        "*  **Gender** - the gender of the immigrants;\n",
        "*  **COU_DEST** - the country of destination (country of residence);\n",
        "*  **Destination Country** - the country of residence;\n",
        "*  **Immigrant Stock** - the number of immigrants (foreign born citizens)\n",
        "*  **Origin Country Population** - the population in the country of origin;\n",
        "*  **Destination Country Population** - the population in the country of destination.\n"
      ],
      "metadata": {
        "id": "hsNM6uGxuuND"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.2 Setting up the data transformation strategy"
      ],
      "metadata": {
        "id": "haJFHoogxakm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We would like to perform the following changes in the data:\n",
        "\n",
        "1.   Filter out the records that are not valid, e.g. with invalid values for the year feature; \n",
        "2.   Encode categorical items;\n",
        "3.   Scale the values for origin and destination country population;\n",
        "4.   Include the Year and Immigrant Stock feature values along with the other processed data; \n",
        "5.   Extract a dataset for estimating (or otherwise imputing) the Immigrant Stock missing values.\n",
        "\n",
        "We would like to proceed with a reusable and composable manner offered by the usage of data pipelines.\n"
      ],
      "metadata": {
        "id": "QEpQqmRi9WuX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1.2.1 Understanding basic data processing concepts"
      ],
      "metadata": {
        "id": "2Gzu0leQg_xI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From a data transformation perspective, the sklearn library uses several out of the box mechanisms to ensure that there are strong, reusable, mechanisms for data transformation:\n",
        "\n",
        "*    Data pipelines represented by the [**Pipeline**](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) class used to assemble together different data transformation steps;\n",
        "*    Column trasformers represented by the [**ColumnTransformer**](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html) class used to transform columnar data from various sources;\n",
        "*    Feature union represented by the [**FeatureUnion**](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.FeatureUnion.html) class that is used to assemble together multiple transformation results.\n",
        "\n",
        "It is also possible for defining custom data transformers for further customizing the data processing mechanisms."
      ],
      "metadata": {
        "id": "5dyJnR4phKVI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1.2.2 Understanding data transformers"
      ],
      "metadata": {
        "id": "jMFK5Vs5jkWA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data transformers are the basic building blocks for implementing data transformation with sklearn.\n",
        "\n",
        "A transformer is based on the following classes:\n",
        "\n",
        "*    [**BaseEstimator**](https://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html) that defines the basic functionality for a transformer (such support for fitting and transforming data);\n",
        "*    [**TransformerMixin**](https://scikit-learn.org/stable/modules/generated/sklearn.base.TransformerMixin.html) which enables additional support, more precisely fitting and transforming data in a single operation.\n",
        "\n",
        "Basically a data transformer should support the following methods:\n",
        "\n",
        "*   **fit(x, y = None, **fit_params)** where the transformer learns patterns of data to use for further transformations. The x parameter represents the input data and the y parameter represents labels for the data (such as in case of supervised learning).\n",
        "\n",
        "In case of simple transformations, learning data pattern is not necessary - so the fit method does nothing in this case. This method returns the transformer whose state has been updated by fitting the input data;\n",
        "\n",
        "*   **transform(x, y = None, **fit_params)** where the transformer receives the input data (x parameter) and returns the transformed data;\n",
        "*   **get_feature_names_out(input_features=None)** returning the names of the transformed features. \n",
        "\n",
        "The TransformerMixin provides also the **fit_transform(X, y=None, **fit_params)** method which calls the **fit** and afterwards the **transform** method on the same data.\n",
        "\n",
        "The ** **fit_params** parameters represent additional parameters that may be provided for the fitting and transforming methods. \n"
      ],
      "metadata": {
        "id": "-zzY0tTCjeqx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1.2.3 Implementing phase 1: filter out the records that are not valid "
      ],
      "metadata": {
        "id": "OJEfRFMEzDbx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's implement the first phase of our data transformation strategy by using a custom transformer."
      ],
      "metadata": {
        "id": "Z-YTVqoyoZah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Phase 1: Encode categorical items related to gender, origin country and destination country\n",
        "\n",
        "class FilterOutTransformer(sklb.BaseEstimator, sklb.TransformerMixin) :\n",
        "  \"\"\"\n",
        "  The filter out transformer will filter out the records that have invalid\n",
        "  values for a set of specified features\n",
        "  \"\"\"\n",
        "  def __init__(self, features_to_filter_out):\n",
        "    self.features_to_filter_out = features_to_filter_out\n",
        "\n",
        "  def fit(self, X, Y = None, ** fit_params) :\n",
        "    return self\n",
        "\n",
        "  def transform(self, X, Y = None, ** fit_params) :\n",
        "    result = X.copy()\n",
        "    for feature in self.features_to_filter_out :\n",
        "      result = result[~np.isnan(result[feature])]\n",
        "    return result\n",
        "\n",
        "  def get_feature_names_out(self, input_features=None) :\n",
        "    return input_features\n",
        "\n",
        "# create a preprocessor for filtering out records\n",
        "# that have invalid values for Year feature\n",
        "filter_out_transformer = FilterOutTransformer([\"Year\"])\n",
        "\n",
        "# process the data\n",
        "filter_out_data_processed = filter_out_transformer.fit_transform(loaded_data)\n",
        "print(\n",
        "    \"A sample of transformed data by filtering out records with invalid Year \\\n",
        "values is \\n {} \\n with shape \\n {}\".format(\n",
        "        filter_out_data_processed[0:10],\n",
        "        filter_out_data_processed.shape\n",
        "    )\n",
        ")\n",
        "\n",
        "# display a sample of the generated featured\n",
        "print(\n",
        "      \"A sample of the features generated by the transformer is \\n{} \".format(\n",
        "        filter_out_transformer.get_feature_names_out(\n",
        "            loaded_data.columns\n",
        "        )[0:10]    \n",
        "      )\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPWn0dBGorKC",
        "outputId": "ff4277af-25a6-4ec0-9e47-2873296f3922"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A sample of transformed data by filtering out records with invalid Year values is \n",
            "      Year COU_ORIG Origin Country Gender COU_DEST Destination Country  Immigrant Stock  Origin Country Population  Destination Country Population\n",
            "0  2000.0      AFG    Afghanistan    MEN      AUS           Australia           6500.0                 20779957.0                      19153000.0\n",
            "1  2001.0      AFG    Afghanistan    MEN      AUS           Australia           7410.0                 21606992.0                      19413000.0\n",
            "2  2002.0      AFG    Afghanistan    MEN      AUS           Australia           8710.0                 22600774.0                      19651400.0\n",
            "3  2003.0      AFG    Afghanistan    MEN      AUS           Australia           9260.0                 23680871.0                      19895400.0\n",
            "4  2004.0      AFG    Afghanistan    MEN      AUS           Australia           9810.0                 24726689.0                      20127400.0\n",
            "5  2005.0      AFG    Afghanistan    MEN      AUS           Australia          10600.0                 25654274.0                      20394800.0\n",
            "6  2006.0      AFG    Afghanistan    MEN      AUS           Australia          12170.0                 26433058.0                      20697900.0\n",
            "7  2007.0      AFG    Afghanistan    MEN      AUS           Australia          13280.0                 27100542.0                      20827600.0\n",
            "8  2008.0      AFG    Afghanistan    MEN      AUS           Australia          14230.0                 27722281.0                      21249200.0\n",
            "9  2009.0      AFG    Afghanistan    MEN      AUS           Australia          15360.0                 28394806.0                      21691700.0 \n",
            " with shape \n",
            " (289674, 9)\n",
            "A sample of the features generated by the transformer is \n",
            "Index(['Year', 'COU_ORIG', 'Origin Country', 'Gender', 'COU_DEST',\n",
            "       'Destination Country', 'Immigrant Stock', 'Origin Country Population',\n",
            "       'Destination Country Population'],\n",
            "      dtype='object') \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1.2.4 Implementing phase 2: encode categorical items"
      ],
      "metadata": {
        "id": "IXKxaaSl059P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The categorical items will be one-hot encoded using out of the box mechanisms. They are represented by the ColumnTransformer data transformer using the standard sklearn's one hot encoder."
      ],
      "metadata": {
        "id": "bHCuXfQ_1Nom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Phase 2: Encode categorical items related to gender, origin country and destination country\n",
        "\n",
        "# determine the categorical features to be one-hot encoded\n",
        "gender_categorical_features = [\"Gender\"]\n",
        "countries_categorical_features = [\"COU_ORIG\", \"COU_DEST\"]\n",
        "\n",
        "# create a pre-processor for categorical features \n",
        "# it is basically a column transformer that applies\n",
        "# a one-hot encoder for the gender variable \n",
        "# and another for the country-related variables\n",
        "categorical_transformer = sklcompose.ColumnTransformer(\n",
        "  transformers = [  \n",
        "    ( \n",
        "      \"gender_encoder\", \n",
        "      sklpre.OneHotEncoder(sparse = False), \n",
        "      gender_categorical_features\n",
        "    ),\n",
        "    (\n",
        "      \"countries_encoder\", \n",
        "      sklpre.OneHotEncoder(sparse = False), \n",
        "      countries_categorical_features\n",
        "    )\n",
        "  ]\n",
        ")\n",
        "\n",
        "# process the data\n",
        "categorical_data_preprocessed = categorical_transformer.fit_transform(loaded_data)\n",
        "print(\n",
        "    \"A sample of transformed data is \\n {} \\n with shape \\n {}\".format(\n",
        "        categorical_data_preprocessed[0:10],\n",
        "        categorical_data_preprocessed.shape\n",
        "    )\n",
        ")\n",
        "\n",
        "# display a sample of the generated featured\n",
        "print(\n",
        "      \"A sample of the features generated by the transformer is \\n{} \".format(\n",
        "        categorical_transformer.get_feature_names_out(\n",
        "            loaded_data.columns\n",
        "        )[0:10]    \n",
        "      )\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHGGd1m3sGGw",
        "outputId": "a3308bd2-10c7-4da1-c080-bfcf04f3e376"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A sample of transformed data is \n",
            " [[1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]] \n",
            " with shape \n",
            " (289675, 247)\n",
            "A sample of the features generated by the transformer is \n",
            "['gender_encoder__Gender_MEN' 'gender_encoder__Gender_WMN'\n",
            " 'gender_encoder__Gender_None' 'countries_encoder__COU_ORIG_AFG'\n",
            " 'countries_encoder__COU_ORIG_AGO' 'countries_encoder__COU_ORIG_ALB'\n",
            " 'countries_encoder__COU_ORIG_AND' 'countries_encoder__COU_ORIG_ARE'\n",
            " 'countries_encoder__COU_ORIG_ARG' 'countries_encoder__COU_ORIG_ARM'] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1.2.5 Implementing phase 3: scale the values for origin and destination country population "
      ],
      "metadata": {
        "id": "erFey9hC1Eye"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The numerical values for origin and destination country population\n",
        "will be scaled using out of the box mechanisms. We will use again the ColumnTransformer data transformer this time with a min-max scaler."
      ],
      "metadata": {
        "id": "F-jNy-qu2Dzh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Phase 3: Scale the values for origin and destination country population \n",
        "\n",
        "# determine the numerical features to be scaled\n",
        "country_numerical_features = [\"Origin Country Population\", \"Destination Country Population\"]\n",
        "\n",
        "# create a pre-processor for categorical features \n",
        "# it is basically a column transformer that applies\n",
        "# min-max scaling for countries population\n",
        "country_numerical_transformer = sklcompose.ColumnTransformer(\n",
        "  transformers = [ \n",
        "    (\n",
        "      \"country_population_scaler\", \n",
        "      sklpre.MinMaxScaler(), \n",
        "      country_numerical_features\n",
        "    )\n",
        "  ]\n",
        ")\n",
        "\n",
        "# process the data\n",
        "country_numerical_data_preprocessed = country_numerical_transformer.fit_transform(loaded_data)\n",
        "\n",
        "# display samples of data along with basic output information \n",
        "print(\n",
        "    \"A sample of transformed data is \\n{}\\n with shape {} \\n\".format(\n",
        "        country_numerical_data_preprocessed[0:10],\n",
        "        country_numerical_data_preprocessed.shape\n",
        "    )\n",
        ")\n",
        "\n",
        "# display a sample of the generated featured\n",
        "print(\n",
        "      \"A sample of the features generated by the transformer is \\n{} \".format(\n",
        "        country_numerical_transformer.get_feature_names_out(\n",
        "            loaded_data.columns\n",
        "        )[0:10]    \n",
        "      )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Snth6R2LmexE",
        "outputId": "c4d06cc7-f284-49de-817e-4836a82bb234"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A sample of transformed data is \n",
            "[[0.01472129 0.05732572]\n",
            " [0.01530746 0.05811551]\n",
            " [0.01601181 0.05883968]\n",
            " [0.01677734 0.05958087]\n",
            " [0.01751857 0.0602856 ]\n",
            " [0.018176   0.06109786]\n",
            " [0.01872797 0.06201857]\n",
            " [0.01920105 0.06241255]\n",
            " [0.01964172 0.06369322]\n",
            " [0.02011837 0.06503738]]\n",
            " with shape (289675, 2) \n",
            "\n",
            "A sample of the features generated by the transformer is \n",
            "['country_population_scaler__Origin Country Population'\n",
            " 'country_population_scaler__Destination Country Population'] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1.2.6 Implementing phase 4: include the Year and Immigrant Stock feature values along with the other processed data"
      ],
      "metadata": {
        "id": "sqfZDe0RAQx8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to extract the values for Year and Immigrant Stock so that we have all the features needed to assemble the dataset. This is not supported out of the box by sklearn so we will need a custom transformer for this purpose."
      ],
      "metadata": {
        "id": "--iq7HngA7Co"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SelectColumnsTransformer(sklb.BaseEstimator, sklb.TransformerMixin) :\n",
        "  \"\"\"\n",
        "  The filter out transformer will filter out the records that have invalid\n",
        "  values for a set of specified features\n",
        "  \"\"\"\n",
        "  def __init__(self, columns_to_select):\n",
        "    self.columns_to_select = columns_to_select\n",
        "\n",
        "  def fit(self, X, Y = None, ** fit_params) :\n",
        "    return self\n",
        "\n",
        "  def transform(self, X, Y = None, ** fit_params) :\n",
        "    result = X.copy()[self.columns_to_select]\n",
        "    return result\n",
        "\n",
        "  def get_feature_names_out(self, input_features=None) :\n",
        "    return self.columns_to_select\n",
        "\n",
        "# preprocess a data sample\n",
        "select_columns_transformer = SelectColumnsTransformer([\"Immigrant Stock\", \"Year\"])\n",
        "select_columns_data_processed =  select_columns_transformer.fit_transform(loaded_data)\n",
        "\n",
        "# display samples of data along with basic output information \n",
        "print(\n",
        "    \"A sample of transformed data is \\n{}\\n with shape {} \\n\".format(\n",
        "        select_columns_data_processed[0:10],\n",
        "        select_columns_data_processed.shape\n",
        "    )\n",
        ")\n",
        "\n",
        "# display a sample of the generated featured\n",
        "print(\n",
        "      \"A sample of the features generated by the transformer is \\n{} \".format(\n",
        "        select_columns_transformer.get_feature_names_out(\n",
        "            loaded_data.columns\n",
        "        )[0:10]    \n",
        "      )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5jCJsfT3X3b",
        "outputId": "9b798e28-7773-4da3-b303-c1aca6904bb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A sample of transformed data is \n",
            "   Immigrant Stock    Year\n",
            "0           6500.0  2000.0\n",
            "1           7410.0  2001.0\n",
            "2           8710.0  2002.0\n",
            "3           9260.0  2003.0\n",
            "4           9810.0  2004.0\n",
            "5          10600.0  2005.0\n",
            "6          12170.0  2006.0\n",
            "7          13280.0  2007.0\n",
            "8          14230.0  2008.0\n",
            "9          15360.0  2009.0\n",
            " with shape (289675, 2) \n",
            "\n",
            "A sample of the features generated by the transformer is \n",
            "['Immigrant Stock', 'Year'] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A this point we have all the segments of data needed to assemble the final dataset:\n",
        "\n",
        "*    We have the values for Year and Immigrant stock;\n",
        "*    We have the one-hot encoded categorical features;\n",
        "*    We have the scaled values for origin and destination country population.\n",
        "\n",
        "These segments of data are joined by using the sklearn's out of the box support represented by FeatureUnion which joins the outputs of multiple transformers."
      ],
      "metadata": {
        "id": "QBro18-qLWk5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Phase 4: include the Year and Immigrant Stock feature values along with the other processed data\n",
        "\n",
        "# use FeatureUnion to assemble multiple outcomes from data transformers\n",
        "# we will pass a list of the transformers for which the outputs\n",
        "# will be joined\n",
        "union_transformer = sklpipe.FeatureUnion(\n",
        "      (\n",
        "        # provides the Year and Immigrant Stock features\n",
        "        (\n",
        "          \"select_columns_transformer\",\n",
        "          select_columns_transformer\n",
        "        ),  \n",
        "        # provides scaled origin and destination country population values  \n",
        "        (\n",
        "          \"country_numerical_transformer\",\n",
        "          country_numerical_transformer\n",
        "        ),\n",
        "        # provides encoded categorical features\n",
        "        (\n",
        "          \"categorical_transformer\",\n",
        "          categorical_transformer\n",
        "        )\n",
        "      )\n",
        "  )\n",
        "\n",
        "# process the data\n",
        "union_data_processed = union_transformer.fit_transform(loaded_data)\n",
        "\n",
        "# display samples of data along with basic output information \n",
        "print(\n",
        "    \"A sample of transformed data is \\n{}\\n with shape {} \\n\".format(\n",
        "        union_data_processed[0:10],\n",
        "        union_data_processed.shape\n",
        "    )\n",
        ")\n",
        "\n",
        "# display a sample of the generated featured\n",
        "print(\n",
        "      \"A sample of the features generated by the transformer is \\n{} \".format(\n",
        "        union_transformer.get_feature_names_out(\n",
        "            loaded_data.columns\n",
        "        )[0:10]    \n",
        "      )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6a2jYmZ4EmJ",
        "outputId": "76822bc0-bda4-4ce4-a8de-b3a0470f4d6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A sample of transformed data is \n",
            "[[6.50000000e+03 2.00000000e+03 1.47212921e-02 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [7.41000000e+03 2.00100000e+03 1.53074593e-02 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [8.71000000e+03 2.00200000e+03 1.60118097e-02 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " ...\n",
            " [1.32800000e+04 2.00700000e+03 1.92010536e-02 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [1.42300000e+04 2.00800000e+03 1.96417158e-02 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [1.53600000e+04 2.00900000e+03 2.01183728e-02 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]]\n",
            " with shape (289675, 251) \n",
            "\n",
            "A sample of the features generated by the transformer is \n",
            "['select_columns_transformer__Immigrant Stock'\n",
            " 'select_columns_transformer__Year'\n",
            " 'country_numerical_transformer__country_population_scaler__Origin Country Population'\n",
            " 'country_numerical_transformer__country_population_scaler__Destination Country Population'\n",
            " 'categorical_transformer__gender_encoder__Gender_MEN'\n",
            " 'categorical_transformer__gender_encoder__Gender_WMN'\n",
            " 'categorical_transformer__gender_encoder__Gender_None'\n",
            " 'categorical_transformer__countries_encoder__COU_ORIG_AFG'\n",
            " 'categorical_transformer__countries_encoder__COU_ORIG_AGO'\n",
            " 'categorical_transformer__countries_encoder__COU_ORIG_ALB'] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1.2.7 Implementing phase 5: extract a dataset for estimating (or otherwise imputing) the Immigrant Stock missing values"
      ],
      "metadata": {
        "id": "PgAiSE0_FTQU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So far we have all the pieces needed to implement Phase 5, we need to put them together. We need to cleanup the data and afterwards use this clean data to generate a dataset for Immigrant Stock feature imputation."
      ],
      "metadata": {
        "id": "MC0KV1XyOHdr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this purpose, we will use another sklearn's out of the box mechanism represented by the Pipeline mechanism.\n",
        "\n",
        "The data pipelines allow the definition and execution of data transformation flows by assembling a set of data transformation steps. "
      ],
      "metadata": {
        "id": "KlJlS9W0OZHh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a data transformation pipeline that \n",
        "# will cleanup the initial data, \n",
        "# trigger data processing (e.g. scaling and encoding)\n",
        "# and finally assemble the result\n",
        "data_transformation_pipeline = sklpipe.Pipeline(\n",
        "    steps = [\n",
        "       (\"data cleanup\", filter_out_transformer),\n",
        "       (\"data processing and assembly\", union_transformer)      \n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "zLp1pRcLO9Q4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display the pipeline in textual format\n",
        "data_transformation_pipeline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2Snw9IwQd_X",
        "outputId": "ad026704-0f6a-4151-f97e-a5ab5352ffc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('data cleanup',\n",
              "                 FilterOutTransformer(features_to_filter_out=['Year'])),\n",
              "                ('data processing and assembly',\n",
              "                 FeatureUnion(transformer_list=[('select_columns_transformer',\n",
              "                                                 SelectColumnsTransformer(columns_to_select=['Immigrant '\n",
              "                                                                                             'Stock',\n",
              "                                                                                             'Year'])),\n",
              "                                                ('country_numerical_transformer',\n",
              "                                                 ColumnTransformer(transformers=[('country_population_scaler',\n",
              "                                                                                  MinMaxScaler(),\n",
              "                                                                                  ['Origin '\n",
              "                                                                                   'Country '\n",
              "                                                                                   'Population',\n",
              "                                                                                   'Destination '\n",
              "                                                                                   'Country '\n",
              "                                                                                   'Population'])])),\n",
              "                                                ('categorical_transformer',\n",
              "                                                 ColumnTransformer(transformers=[('gender_encoder',\n",
              "                                                                                  OneHotEncoder(sparse=False),\n",
              "                                                                                  ['Gender']),\n",
              "                                                                                 ('countries_encoder',\n",
              "                                                                                  OneHotEncoder(sparse=False),\n",
              "                                                                                  ['COU_ORIG',\n",
              "                                                                                   'COU_DEST'])]))]))])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# process the dataset\n",
        "data_processed = data_transformation_pipeline.fit_transform(loaded_data)\n",
        "\n",
        "# display samples of data along with basic output information \n",
        "print(\n",
        "    \"A sample of data generated by the data pipeline is is \\n{}\\n with shape {} \\n\".format(\n",
        "        data_processed[0:10],\n",
        "        data_processed.shape\n",
        "    )\n",
        ")\n",
        "\n",
        "# display a sample of the generated featured\n",
        "print(\n",
        "      \"A sample of the features generated by the data pipeline is \\n{}\".format(\n",
        "        data_transformation_pipeline.get_feature_names_out(\n",
        "            loaded_data.columns\n",
        "        )[0:10]    \n",
        "      )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVeM5EoySNqv",
        "outputId": "df366714-9f4c-4dab-b457-cb7be1369494"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A sample of data generated by the data pipeline is is \n",
            "[[6.50000000e+03 2.00000000e+03 1.47212921e-02 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [7.41000000e+03 2.00100000e+03 1.53074593e-02 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [8.71000000e+03 2.00200000e+03 1.60118097e-02 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " ...\n",
            " [1.32800000e+04 2.00700000e+03 1.92010536e-02 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [1.42300000e+04 2.00800000e+03 1.96417158e-02 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [1.53600000e+04 2.00900000e+03 2.01183728e-02 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]]\n",
            " with shape (289674, 248) \n",
            "\n",
            "A sample of the features generated by the data pipeline is \n",
            "['select_columns_transformer__Immigrant Stock'\n",
            " 'select_columns_transformer__Year'\n",
            " 'country_numerical_transformer__country_population_scaler__Origin Country Population'\n",
            " 'country_numerical_transformer__country_population_scaler__Destination Country Population'\n",
            " 'categorical_transformer__gender_encoder__Gender_MEN'\n",
            " 'categorical_transformer__gender_encoder__Gender_WMN'\n",
            " 'categorical_transformer__countries_encoder__COU_ORIG_AFG'\n",
            " 'categorical_transformer__countries_encoder__COU_ORIG_AGO'\n",
            " 'categorical_transformer__countries_encoder__COU_ORIG_ALB'\n",
            " 'categorical_transformer__countries_encoder__COU_ORIG_AND']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a dataframe with the processed results\n",
        "processed_dataset = pd.DataFrame(\n",
        "  columns = data_transformation_pipeline.get_feature_names_out(loaded_data.columns),\n",
        "  data = data_processed\n",
        ") \n",
        "\n",
        "# display samples of data along with basic output information \n",
        "print(\n",
        "      \"A sample of the processed dataset is \\n{} \".format(\n",
        "          processed_dataset[0:10]\n",
        "      )\n",
        ")\n",
        "\n",
        "# at this point we can use the processed data for any machine learning pursposes\n",
        "# e.g. imputing or predicting values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWu2XA6MSxPq",
        "outputId": "29f03141-f250-43e5-fa79-a43556dbdc28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A sample of the processed dataset is \n",
            "   select_columns_transformer__Immigrant Stock  select_columns_transformer__Year  country_numerical_transformer__country_population_scaler__Origin Country Population  country_numerical_transformer__country_population_scaler__Destination Country Population  categorical_transformer__gender_encoder__Gender_MEN  categorical_transformer__gender_encoder__Gender_WMN  categorical_transformer__countries_encoder__COU_ORIG_AFG  categorical_transformer__countries_encoder__COU_ORIG_AGO  categorical_transformer__countries_encoder__COU_ORIG_ALB  categorical_transformer__countries_encoder__COU_ORIG_AND  categorical_transformer__countries_encoder__COU_ORIG_ARE  categorical_transformer__countries_encoder__COU_ORIG_ARG  categorical_transformer__countries_encoder__COU_ORIG_ARM  categorical_transformer__countries_encoder__COU_ORIG_ATG  categorical_transformer__countries_encoder__COU_ORIG_AUS  categorical_transformer__countries_encoder__COU_ORIG_AUT  categorical_transformer__countries_encoder__COU_ORIG_AZE  categorical_transformer__countries_encoder__COU_ORIG_BDI  categorical_transformer__countries_encoder__COU_ORIG_BEL  categorical_transformer__countries_encoder__COU_ORIG_BEN  categorical_transformer__countries_encoder__COU_ORIG_BFA  categorical_transformer__countries_encoder__COU_ORIG_BGD  categorical_transformer__countries_encoder__COU_ORIG_BGR  categorical_transformer__countries_encoder__COU_ORIG_BHR  categorical_transformer__countries_encoder__COU_ORIG_BHS  categorical_transformer__countries_encoder__COU_ORIG_BIH  categorical_transformer__countries_encoder__COU_ORIG_BLR  categorical_transformer__countries_encoder__COU_ORIG_BLZ  categorical_transformer__countries_encoder__COU_ORIG_BMU  categorical_transformer__countries_encoder__COU_ORIG_BOL  categorical_transformer__countries_encoder__COU_ORIG_BRA  categorical_transformer__countries_encoder__COU_ORIG_BRB  categorical_transformer__countries_encoder__COU_ORIG_BRN  categorical_transformer__countries_encoder__COU_ORIG_BTN  categorical_transformer__countries_encoder__COU_ORIG_BWA  categorical_transformer__countries_encoder__COU_ORIG_CAF  categorical_transformer__countries_encoder__COU_ORIG_CAN  categorical_transformer__countries_encoder__COU_ORIG_CHE  categorical_transformer__countries_encoder__COU_ORIG_CHL  categorical_transformer__countries_encoder__COU_ORIG_CHN  ...  categorical_transformer__countries_encoder__COU_ORIG_WSM  categorical_transformer__countries_encoder__COU_ORIG_YEM  categorical_transformer__countries_encoder__COU_ORIG_YUCS  categorical_transformer__countries_encoder__COU_ORIG_YYY  categorical_transformer__countries_encoder__COU_ORIG_ZAF  categorical_transformer__countries_encoder__COU_ORIG_ZMB  categorical_transformer__countries_encoder__COU_ORIG_ZWE  categorical_transformer__countries_encoder__COU_DEST_AUS  categorical_transformer__countries_encoder__COU_DEST_AUT  categorical_transformer__countries_encoder__COU_DEST_BEL  categorical_transformer__countries_encoder__COU_DEST_CAN  categorical_transformer__countries_encoder__COU_DEST_CHE  categorical_transformer__countries_encoder__COU_DEST_CHL  categorical_transformer__countries_encoder__COU_DEST_CZE  categorical_transformer__countries_encoder__COU_DEST_DEU  categorical_transformer__countries_encoder__COU_DEST_DNK  categorical_transformer__countries_encoder__COU_DEST_ESP  categorical_transformer__countries_encoder__COU_DEST_EST  categorical_transformer__countries_encoder__COU_DEST_FIN  categorical_transformer__countries_encoder__COU_DEST_FRA  categorical_transformer__countries_encoder__COU_DEST_GBR  categorical_transformer__countries_encoder__COU_DEST_GRC  categorical_transformer__countries_encoder__COU_DEST_HUN  categorical_transformer__countries_encoder__COU_DEST_IRL  categorical_transformer__countries_encoder__COU_DEST_ISL  categorical_transformer__countries_encoder__COU_DEST_ISR  categorical_transformer__countries_encoder__COU_DEST_ITA  categorical_transformer__countries_encoder__COU_DEST_LUX  categorical_transformer__countries_encoder__COU_DEST_LVA  categorical_transformer__countries_encoder__COU_DEST_MEX  categorical_transformer__countries_encoder__COU_DEST_NLD  categorical_transformer__countries_encoder__COU_DEST_NOR  categorical_transformer__countries_encoder__COU_DEST_NZL  categorical_transformer__countries_encoder__COU_DEST_POL  categorical_transformer__countries_encoder__COU_DEST_PRT  categorical_transformer__countries_encoder__COU_DEST_SVK  categorical_transformer__countries_encoder__COU_DEST_SVN  categorical_transformer__countries_encoder__COU_DEST_SWE  categorical_transformer__countries_encoder__COU_DEST_TUR  categorical_transformer__countries_encoder__COU_DEST_USA\n",
            "0                                       6500.0                            2000.0                                           0.014721                                                                             0.057326                                                                                       1.0                                                  0.0                                                  1.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0         ...                                                0.0                                                       0.0                                                       0.0                                                        0.0                                                       0.0                                                       0.0                                                       0.0                                                       1.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0       \n",
            "1                                       7410.0                            2001.0                                           0.015307                                                                             0.058116                                                                                       1.0                                                  0.0                                                  1.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0         ...                                                0.0                                                       0.0                                                       0.0                                                        0.0                                                       0.0                                                       0.0                                                       0.0                                                       1.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0       \n",
            "2                                       8710.0                            2002.0                                           0.016012                                                                             0.058840                                                                                       1.0                                                  0.0                                                  1.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0         ...                                                0.0                                                       0.0                                                       0.0                                                        0.0                                                       0.0                                                       0.0                                                       0.0                                                       1.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0       \n",
            "3                                       9260.0                            2003.0                                           0.016777                                                                             0.059581                                                                                       1.0                                                  0.0                                                  1.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0         ...                                                0.0                                                       0.0                                                       0.0                                                        0.0                                                       0.0                                                       0.0                                                       0.0                                                       1.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0       \n",
            "4                                       9810.0                            2004.0                                           0.017519                                                                             0.060286                                                                                       1.0                                                  0.0                                                  1.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0         ...                                                0.0                                                       0.0                                                       0.0                                                        0.0                                                       0.0                                                       0.0                                                       0.0                                                       1.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0       \n",
            "5                                      10600.0                            2005.0                                           0.018176                                                                             0.061098                                                                                       1.0                                                  0.0                                                  1.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0         ...                                                0.0                                                       0.0                                                       0.0                                                        0.0                                                       0.0                                                       0.0                                                       0.0                                                       1.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0       \n",
            "6                                      12170.0                            2006.0                                           0.018728                                                                             0.062019                                                                                       1.0                                                  0.0                                                  1.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0         ...                                                0.0                                                       0.0                                                       0.0                                                        0.0                                                       0.0                                                       0.0                                                       0.0                                                       1.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0       \n",
            "7                                      13280.0                            2007.0                                           0.019201                                                                             0.062413                                                                                       1.0                                                  0.0                                                  1.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0         ...                                                0.0                                                       0.0                                                       0.0                                                        0.0                                                       0.0                                                       0.0                                                       0.0                                                       1.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0       \n",
            "8                                      14230.0                            2008.0                                           0.019642                                                                             0.063693                                                                                       1.0                                                  0.0                                                  1.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0         ...                                                0.0                                                       0.0                                                       0.0                                                        0.0                                                       0.0                                                       0.0                                                       0.0                                                       1.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0       \n",
            "9                                      15360.0                            2009.0                                           0.020118                                                                             0.065037                                                                                       1.0                                                  0.0                                                  1.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0         ...                                                0.0                                                       0.0                                                       0.0                                                        0.0                                                       0.0                                                       0.0                                                       0.0                                                       1.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0                                                       0.0       \n",
            "\n",
            "[10 rows x 248 columns] \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "004_SciKit_Learn_Data_Pipelines.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}