{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDuU6OSWXKo4"
      },
      "source": [
        "![*INTERTECHNICA - SOLON EDUCATIONAL PROGRAMS - TECHNOLOGY LINE*](https://solon.intertechnica.com/assets/IntertechnicaSolonEducationalPrograms-TechnologyLine.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeBbVwSSXKo9"
      },
      "source": [
        "# Data Manipulation with Python - Advanced Data Manipulation - Data Imputation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUhqqWdPXKpA"
      },
      "source": [
        "*Basic initialization of the workspace.*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install numpy\n",
        "import numpy as np\n",
        "print (\"NumPy installed at version: {}\".format(np.__version__))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJzCFKioH6UR",
        "outputId": "17bc2847-b74f-401e-e82e-abdfb01557ea"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "NumPy installed at version: 1.19.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "AjAZRU7GXKpE",
        "outputId": "d0983641-e9b6-465d-bb7a-e8f25d301c09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Pandas installed at version: 1.3.5\n"
          ]
        }
      ],
      "source": [
        "!python -m pip install pandas\n",
        "import pandas as pd\n",
        "print (\"Pandas installed at version: {}\".format(pd.__version__))\n",
        "\n",
        "#adjust pandas DataFrame display for a wider target \n",
        "pd.set_option('display.expand_frame_repr', False)\n",
        "\n",
        "# disable warnings for chained assignment\n",
        "pd.set_option('mode.chained_assignment', None)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install sklearn\n",
        "import sklearn as skl\n",
        "import sklearn.experimental as skle\n",
        "import sklearn.impute as skli\n",
        "\n",
        "print (\"Sklearn installed at version: {}\".format(skl.__version__))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbyxoZM02V84",
        "outputId": "13de277e-6619-4f44-d453-70b26070687f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.0.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.19.5)\n",
            "Sklearn installed at version: 1.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1 Loading Data"
      ],
      "metadata": {
        "id": "mPYkEjtYty65"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will focus on processing a dataset focused on immigration data. It contains the number of foreign born citizens in different countries, considering different genders in different years. \n",
        "\n",
        "The dataset has missing values for a critical feature: the stock of citizens with a foreign origin/nationality.\n"
      ],
      "metadata": {
        "id": "jCNn1Jk-t2gz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.1 Loading and exploring data"
      ],
      "metadata": {
        "id": "PrWXFgFiugmV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First of all, loading data and basic exploration of the dataset structure is required. "
      ],
      "metadata": {
        "id": "iQYKBLNHuZ6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load raw data for processing\n",
        "raw_data = pd.read_parquet(\n",
        "    \"https://github.com/INTERTECHNICA-BUSINESS-SOLUTIONS-SRL/CourseDataManipulationWithPython/raw/main/Module%204%20-%20Advanced%20Data%20Manipulation/Session%202%20-%20Advanced%20Data%20Manipulation/data/migration_dataset_extended.parquet\"\n",
        ")\n",
        "\n",
        "print(\n",
        "    \"A sample of of raw data is \\n {}\".format(\n",
        "      raw_data[0:10]  \n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "mQy9EwjetX3W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06dd1567-d05b-4338-a01b-247489c5da81"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A sample of of raw data is \n",
            "      Year COU_ORIG Origin Country Gender COU_DEST Destination Country  Immigrant Stock  Origin Country Population  Destination Country Population\n",
            "0  2000.0      AFG    Afghanistan    MEN      AUS           Australia           6500.0                 20779957.0                      19153000.0\n",
            "1  2001.0      AFG    Afghanistan    MEN      AUS           Australia           7410.0                 21606992.0                      19413000.0\n",
            "2  2002.0      AFG    Afghanistan    MEN      AUS           Australia           8710.0                 22600774.0                      19651400.0\n",
            "3  2003.0      AFG    Afghanistan    MEN      AUS           Australia           9260.0                 23680871.0                      19895400.0\n",
            "4  2004.0      AFG    Afghanistan    MEN      AUS           Australia           9810.0                 24726689.0                      20127400.0\n",
            "5  2005.0      AFG    Afghanistan    MEN      AUS           Australia          10600.0                 25654274.0                      20394800.0\n",
            "6  2006.0      AFG    Afghanistan    MEN      AUS           Australia          12170.0                 26433058.0                      20697900.0\n",
            "7  2007.0      AFG    Afghanistan    MEN      AUS           Australia          13280.0                 27100542.0                      20827600.0\n",
            "8  2008.0      AFG    Afghanistan    MEN      AUS           Australia          14230.0                 27722281.0                      21249200.0\n",
            "9  2009.0      AFG    Afghanistan    MEN      AUS           Australia          15360.0                 28394806.0                      21691700.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can observe that the dataset has several features:\n",
        "\n",
        "*  **Year** - the year of observation;\n",
        "*  **COU_ORIG** - the ISO3 code for the country of origin;\n",
        "*  **Origin Country** - the name of the country of origin (country of birth/nationality);\n",
        "*  **Gender** - the gender of the immigrants;\n",
        "*  **COU_DEST** - the country of destination (country of residence);\n",
        "*  **Destination Country** - the country of residence;\n",
        "*  **Immigrant Stock** - the number of immigrants (foreign born citizens)\n",
        "*  **Origin Country Population** - the population in the country of origin;\n",
        "*  **Destination Country Population** - the population in the country of destination.\n",
        "\n",
        "Several of these features have missing features."
      ],
      "metadata": {
        "id": "hsNM6uGxuuND"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.2 Deciding which data to drop and which data to keep"
      ],
      "metadata": {
        "id": "haJFHoogxakm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will explore the data that has missing data on the features we need as a basic minimum: **Year**, **COU_ORIG**, **COU_DEST**, **Gender**. This data will be dropped outright as we cannot handle it at all. "
      ],
      "metadata": {
        "id": "2K2Z2vMuwF4K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# identify the records to be dropped\n",
        "print(\n",
        "    \"The count of records to be dropped as totally invalid is {}\".format(\n",
        "      raw_data[\n",
        "          np.isnan(raw_data[\"Year\"]) |\n",
        "          pd.isnull(raw_data[\"COU_ORIG\"]) |\n",
        "          pd.isnull(raw_data[\"COU_DEST\"]) |\n",
        "          pd.isnull(raw_data[\"Gender\"])\n",
        "      ].shape[0]    \n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4whchZTw6_E",
        "outputId": "8f4ccd40-b775-4346-aa73-83fc811e7441"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The count of records to be dropped as totally invalid is 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# keep basic valid data\n",
        "basic_valid_data = raw_data[\n",
        "         ~(\n",
        "              np.isnan(raw_data[\"Year\"]) |\n",
        "              pd.isnull(raw_data[\"COU_ORIG\"]) |\n",
        "              pd.isnull(raw_data[\"COU_DEST\"]) |\n",
        "              pd.isnull(raw_data[\"Gender\"])\n",
        "         )    \n",
        "]"
      ],
      "metadata": {
        "id": "nFBysEhOzOx2"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To ensure a better descriptive power of data, we will consider adding a data indicator **Immigant Stock Missing Indicator** to flag records with missing values."
      ],
      "metadata": {
        "id": "jGws4c7oZTbC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set missing indicator if immigant stock information is missing\n",
        "basic_valid_data[\"Immigant Stock Missing Indicator\"] = [1 if np.isnan(value) else 0 for value in basic_valid_data[\"Immigrant Stock\"] ]\n",
        "\n",
        "print(\n",
        "    \"A sample of data with the information of missing data for Immigrant Stock is \\n {}\".format(\n",
        "      basic_valid_data[0:10]  \n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yzRKCekzlbN",
        "outputId": "eea1d06a-2a24-490f-8cd4-f2e3a60e3e8f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A sample of data with the information of missing data for Immigrant Stock is \n",
            "      Year COU_ORIG Origin Country Gender COU_DEST Destination Country  Immigrant Stock  Origin Country Population  Destination Country Population  Immigant Stock Missing Indicator\n",
            "0  2000.0      AFG    Afghanistan    MEN      AUS           Australia           6500.0                 20779957.0                      19153000.0                                 0\n",
            "1  2001.0      AFG    Afghanistan    MEN      AUS           Australia           7410.0                 21606992.0                      19413000.0                                 0\n",
            "2  2002.0      AFG    Afghanistan    MEN      AUS           Australia           8710.0                 22600774.0                      19651400.0                                 0\n",
            "3  2003.0      AFG    Afghanistan    MEN      AUS           Australia           9260.0                 23680871.0                      19895400.0                                 0\n",
            "4  2004.0      AFG    Afghanistan    MEN      AUS           Australia           9810.0                 24726689.0                      20127400.0                                 0\n",
            "5  2005.0      AFG    Afghanistan    MEN      AUS           Australia          10600.0                 25654274.0                      20394800.0                                 0\n",
            "6  2006.0      AFG    Afghanistan    MEN      AUS           Australia          12170.0                 26433058.0                      20697900.0                                 0\n",
            "7  2007.0      AFG    Afghanistan    MEN      AUS           Australia          13280.0                 27100542.0                      20827600.0                                 0\n",
            "8  2008.0      AFG    Afghanistan    MEN      AUS           Australia          14230.0                 27722281.0                      21249200.0                                 0\n",
            "9  2009.0      AFG    Afghanistan    MEN      AUS           Australia          15360.0                 28394806.0                      21691700.0                                 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to identify for each combination of (\"COU_ORIG\", \"COU_DEST\", \"Gender\") how many years have a missing value in report to the total number of records associated with the combination. "
      ],
      "metadata": {
        "id": "mlOqm38WtE5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# aggregate count of records with existing Immigrant Stock value \n",
        "# versus the count of records for each combination of\n",
        "# (\"COU_ORIG\", \"COU_DEST\", \"Gender\")  \n",
        "missing_value_aggregate = basic_valid_data.groupby(\n",
        "    [\"COU_ORIG\", \"COU_DEST\", \"Gender\"]\n",
        ").agg(\n",
        "        count_records = (\"Immigant Stock Missing Indicator\", \"count\"),\n",
        "        count_missing_records = (\"Immigant Stock Missing Indicator\", \"sum\")       \n",
        "  )\n",
        "\n",
        "print(\n",
        "    \"A sample of data with the information of cont of missing data records versus all records \\\n",
        "    in a combination of ('COU_ORIG', 'COU_DEST', 'Gender') is \\n {}\".format(\n",
        "      missing_value_aggregate[0:20]  \n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "x4Uwl5iL0kwz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63aab2b6-3a6b-4b6a-f808-2d2e50fc7f87"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A sample of data with the information of cont of missing data records versus all records     in a combination of ('COU_ORIG', 'COU_DEST', 'Gender') is \n",
            "                           count_records  count_missing_records\n",
            "COU_ORIG COU_DEST Gender                                      \n",
            "AFG      AUS      MEN                21                      0\n",
            "                  WMN                21                      0\n",
            "         AUT      MEN                21                      2\n",
            "                  WMN                21                      2\n",
            "         BEL      MEN                21                     12\n",
            "                  WMN                21                     12\n",
            "         CAN      MEN                21                     18\n",
            "                  WMN                21                     19\n",
            "         CHE      MEN                21                     10\n",
            "                  WMN                21                     10\n",
            "         CHL      MEN                21                     19\n",
            "                  WMN                21                     20\n",
            "         CZE      MEN                21                     20\n",
            "                  WMN                21                     20\n",
            "         DEU      MEN                21                      6\n",
            "                  WMN                21                      6\n",
            "         DNK      MEN                21                      0\n",
            "                  WMN                21                      0\n",
            "         ESP      MEN                21                      8\n",
            "                  WMN                21                      8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For a better usage of data we will need to flatten the aggregate information into a standard data frame, this can be done by the [**reset_index**](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reset_index.html) function.\n",
        "\n",
        "Once this is done, we will also calculate the ratio of missing records towards all existing records for each combination of interest."
      ],
      "metadata": {
        "id": "8IBP5f2iyXj5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reset index from aggregate\n",
        "missing_value_combinations = missing_value_aggregate.reset_index()\n",
        "\n",
        "# count ration missing records\n",
        "missing_value_combinations[\"ratio_missing_records\"] = missing_value_combinations[\"count_missing_records\"] / missing_value_combinations[\"count_records\"]\n",
        "\n",
        "# ignore data with no missing records\n",
        "missing_value_combinations =  missing_value_combinations[missing_value_combinations[\"ratio_missing_records\"] > 0]\n",
        "\n",
        "print(\n",
        "    \"A sample of missing data statistics information is \\n {}\".format(\n",
        "      missing_value_combinations[0:10]  \n",
        "    )\n",
        ")\n",
        "\n",
        "print(\n",
        "    \"There are in total {} combinations to be analysed\".format(\n",
        "        missing_value_combinations.shape[0]\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Licydi9j3Rcj",
        "outputId": "a7830002-123a-4c9d-d56a-b9571f8e4f4d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A sample of missing data statistics information is \n",
            "    COU_ORIG COU_DEST Gender  count_records  count_missing_records  ratio_missing_records\n",
            "2       AFG      AUT    MEN             21                      2               0.095238\n",
            "3       AFG      AUT    WMN             21                      2               0.095238\n",
            "4       AFG      BEL    MEN             21                     12               0.571429\n",
            "5       AFG      BEL    WMN             21                     12               0.571429\n",
            "6       AFG      CAN    MEN             21                     18               0.857143\n",
            "7       AFG      CAN    WMN             21                     19               0.904762\n",
            "8       AFG      CHE    MEN             21                     10               0.476190\n",
            "9       AFG      CHE    WMN             21                     10               0.476190\n",
            "10      AFG      CHL    MEN             21                     19               0.904762\n",
            "11      AFG      CHL    WMN             21                     20               0.952381\n",
            "There are in total 11253 combinations to be analysed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A this point we decide to address only the combination that has a ratio of missing records of 0.4 or less. This is an empirical decision, ratio can vary depending on the data analyst and business needs.\n",
        "\n",
        "Therefore we will leave all the combinations having a ratio of more than 0.4 as is, for the rest we will used data imputation in order to replace missing values with estimated ones.  "
      ],
      "metadata": {
        "id": "WTzziYA905iI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# add the imputed Immigrant Stock value\n",
        "basic_valid_data[\"Immigrant Stock Imputed\"] = np.nan\n",
        "basic_valid_data = basic_valid_data.reindex(\n",
        "    columns = [\n",
        "               \"Year\",\n",
        "               \"COU_ORIG\",\n",
        "               \"Origin Country\",\n",
        "               \"Gender\", \n",
        "               \"COU_DEST\",\n",
        "               \"Destination Country\",\n",
        "               \"Immigrant Stock\",\n",
        "               \"Immigrant Stock Imputed\",\n",
        "               \"Immigant Stock Missing Indicator\",\n",
        "               \"Origin Country Population\",\n",
        "               \"Destination Country Population\"\n",
        "    ]\n",
        ")\n",
        "\n",
        "# keep only the combinations with a ratio of missing records of at most 0.4\n",
        "missing_value_combinations_imputation = missing_value_combinations[missing_value_combinations[\"ratio_missing_records\"] <= 0.4]\n",
        "\n",
        "# drop the columns that are missing\n",
        "missing_value_combinations_imputation = missing_value_combinations_imputation.drop(\n",
        "    [\"count_records\", \"count_missing_records\", \"ratio_missing_records\"],\n",
        "    axis = 1\n",
        "  )\n",
        "\n",
        "print(\n",
        "    \"The count of combinations for which we will try to attempt imputation is {}\".format(\n",
        "        missing_value_combinations_imputation.shape[0]\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7l3XeKa1b_B",
        "outputId": "23946b98-49f0-4e08-cea2-cb420c9be209"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The count of combinations for which we will try to attempt imputation is 2383\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.3 Performing data imputation"
      ],
      "metadata": {
        "id": "7hVhYyVA2QEz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use the imputers from the Sklearn package. One of these imputers is the [**SimpleImputer**](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html#sklearn.impute.SimpleImputer) which allows basic data imputation using mean, median or a constant value.\n",
        "\n",
        "We intend to impute data within each (\"COU_ORIG\", \"COU_DEST\", \"Gender\") combination selected for imputation, the strategy would be to use median data imputation."
      ],
      "metadata": {
        "id": "XO9_bd0oenqk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we will use the simple imputer with the strategy\n",
        "# to impute the median value for missing data\n",
        "simple_imputer = skli.SimpleImputer(\n",
        "  missing_values= np.nan,  \n",
        "  strategy = \"median\",\n",
        "  verbose = 1   \n",
        ")\n",
        "\n",
        "# as an example - impute the first (\"COU_ORIG\", \"COU_DEST\", \"Gender\")\n",
        "# combination selected for imputing\n",
        "missing_value_combination = missing_value_combinations_imputation.values[0]\n",
        "\n",
        "# extract relevant data\n",
        "country_origin = missing_value_combination[0]\n",
        "country_destination = missing_value_combination[1]\n",
        "gender = missing_value_combination[2]\n",
        "\n",
        "# slice from full data for the \n",
        "# combination selected for imputing\n",
        "slice_for_imputation = basic_valid_data[\n",
        "  (basic_valid_data[\"COU_ORIG\"] == country_origin)\n",
        "  &\n",
        "  (basic_valid_data[\"COU_DEST\"] == country_destination)\n",
        "  &\n",
        "  (basic_valid_data[\"Gender\"] == gender)\n",
        "]\n",
        "\n",
        "# extract values for imputation, we only need the \"Immigrant Stock\" feature \n",
        "values_to_transform = slice_for_imputation[\"Immigrant Stock\"].values\n",
        "\n",
        "# fit and transform values for imputation\n",
        "transformed_values = simple_imputer.fit_transform(values_to_transform.reshape(-1, 1))\n",
        "\n",
        "# extract in a meaningful way the transformed values\n",
        "# make sure they represent an integer\n",
        "transformed_values = transformed_values.reshape(1, -1)[0]\n",
        "transformed_values = transformed_values.astype(np.int32)\n",
        "\n",
        "# set the imputer values back in the full data frame\n",
        "basic_valid_data.loc[slice_for_imputation.index, \"Immigrant Stock Imputed\"] = transformed_values\n",
        "\n",
        "# display the data slice for edification\n",
        "print(\n",
        "      \"The transformed data slice is \\n{}\".format(\n",
        "          basic_valid_data.loc[slice_for_imputation.index]\n",
        "      )\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fxBd61Z2TlU",
        "outputId": "2094e2e7-73a4-457a-c275-cb34931768ec"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The transformed data slice is \n",
            "      Year COU_ORIG Origin Country Gender COU_DEST Destination Country  Immigrant Stock  Immigrant Stock Imputed  Immigant Stock Missing Indicator  Origin Country Population  Destination Country Population\n",
            "21  2000.0      AFG    Afghanistan    MEN      AUT             Austria              NaN                   5650.0                                 1                 20779957.0                       8011566.0\n",
            "22  2001.0      AFG    Afghanistan    MEN      AUT             Austria              NaN                   5650.0                                 1                 21606992.0                       8042293.0\n",
            "23  2002.0      AFG    Afghanistan    MEN      AUT             Austria           1710.0                   1710.0                                 0                 22600774.0                       8081957.0\n",
            "24  2003.0      AFG    Afghanistan    MEN      AUT             Austria           2112.0                   2112.0                                 0                 23680871.0                       8121423.0\n",
            "25  2004.0      AFG    Afghanistan    MEN      AUT             Austria           2412.0                   2412.0                                 0                 24726689.0                       8171966.0\n",
            "26  2005.0      AFG    Afghanistan    MEN      AUT             Austria           2737.0                   2737.0                                 0                 25654274.0                       8227829.0\n",
            "27  2006.0      AFG    Afghanistan    MEN      AUT             Austria           3056.0                   3056.0                                 0                 26433058.0                       8268641.0\n",
            "28  2007.0      AFG    Afghanistan    MEN      AUT             Austria           3293.0                   3293.0                                 0                 27100542.0                       8295487.0\n",
            "29  2008.0      AFG    Afghanistan    MEN      AUT             Austria           3581.0                   3581.0                                 0                 27722281.0                       8321496.0\n",
            "30  2009.0      AFG    Afghanistan    MEN      AUT             Austria           4175.0                   4175.0                                 0                 28394806.0                       8343323.0\n",
            "31  2010.0      AFG    Afghanistan    MEN      AUT             Austria           5003.0                   5003.0                                 0                 29185511.0                       8363404.0\n",
            "32  2011.0      AFG    Afghanistan    MEN      AUT             Austria           5650.0                   5650.0                                 0                 30117411.0                       8391643.0\n",
            "33  2012.0      AFG    Afghanistan    MEN      AUT             Austria           7568.0                   7568.0                                 0                 31161378.0                       8429991.0\n",
            "34  2013.0      AFG    Afghanistan    MEN      AUT             Austria           9578.0                   9578.0                                 0                 32269592.0                       8479823.0\n",
            "35  2014.0      AFG    Afghanistan    MEN      AUT             Austria          12458.0                  12458.0                                 0                 33370804.0                       8546356.0\n",
            "36  2015.0      AFG    Afghanistan    MEN      AUT             Austria          13892.0                  13892.0                                 0                 34413603.0                       8642699.0\n",
            "37  2016.0      AFG    Afghanistan    MEN      AUT             Austria          25673.0                  25673.0                                 0                 35383028.0                       8736668.0\n",
            "38  2017.0      AFG    Afghanistan    MEN      AUT             Austria          31232.0                  31232.0                                 0                 36296111.0                       8797566.0\n",
            "39  2018.0      AFG    Afghanistan    MEN      AUT             Austria          30795.0                  30795.0                                 0                 37171922.0                       8840521.0\n",
            "40  2019.0      AFG    Afghanistan    MEN      AUT             Austria          29303.0                  29303.0                                 0                 38041757.0                       8879920.0\n",
            "41  2020.0      AFG    Afghanistan    MEN      AUT             Austria          28020.0                  28020.0                                 0                 38928341.0                       8917205.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can observe that the simple imputer did not generate credible data, in an empirical manner the value for immigrant stock appear to be quite large for the associated years.\n",
        "\n",
        "We can use also the [**IterativeImputer**](https://scikit-learn.org/stable/modules/generated/sklearn.impute.IterativeImputer.html#sklearn.impute.IterativeImputer) which will consider additional features (like year) in order to consider data patterns and trends for imputation."
      ],
      "metadata": {
        "id": "pivWiTaoU2rA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# enable iterative imputer\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "\n",
        "# we will use an iterative imputer which will consider also the \n",
        "# Year feature in addition to the Immigrant Stock one \n",
        "iterative_imputer = skli.IterativeImputer(\n",
        "  missing_values= np.nan,\n",
        "  random_state= 0  \n",
        ")\n",
        "\n",
        "# reset the imputed values\n",
        "basic_valid_data[\"Immigrant Stock Imputed\"] = np.nan\n",
        "\n",
        "# as an example - impute the 10th (\"COU_ORIG\", \"COU_DEST\", \"Gender\")\n",
        "# combination selected for imputing\n",
        "missing_value_combination = missing_value_combinations_imputation.values[9]\n",
        "\n",
        "# extract relevant data\n",
        "country_origin = missing_value_combination[0]\n",
        "country_destination = missing_value_combination[1]\n",
        "gender = missing_value_combination[2]\n",
        "\n",
        "# slice from full data for the \n",
        "# combination selected for imputing\n",
        "slice_for_imputation = basic_valid_data[\n",
        "  (basic_valid_data[\"COU_ORIG\"] == country_origin)\n",
        "  &\n",
        "  (basic_valid_data[\"COU_DEST\"] == country_destination)\n",
        "  &\n",
        "  (basic_valid_data[\"Gender\"] == gender)\n",
        "]\n",
        "\n",
        "# we will consider both \"Year\" and \"Immigrant Stock\" for imputation\n",
        "values_to_transform = slice_for_imputation[[\"Year\", \"Immigrant Stock\"]].values\n",
        "\n",
        "# fit and transform values for imputation\n",
        "transformed_values = iterative_imputer.fit_transform(values_to_transform)\n",
        "\n",
        "# extract in a meaningful way the transformed values\n",
        "# make sure they represent an integer\n",
        "transformed_values = transformed_values\n",
        "transformed_values = transformed_values.astype(np.int32)\n",
        "\n",
        "# set the imputer values back in the full data frame\n",
        "basic_valid_data.loc[slice_for_imputation.index, \"Immigrant Stock Imputed\"] = transformed_values[:, 1]\n",
        "\n",
        "# display the data slice for edification\n",
        "print(\n",
        "      \"The transformed data slice is \\n{}\".format(\n",
        "          basic_valid_data.loc[slice_for_imputation.index]\n",
        "      )\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwGMxB2zWlbv",
        "outputId": "2e4538c1-4c3d-4237-fa55-0ef2bdd9b939"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The transformed data slice is \n",
            "        Year COU_ORIG Origin Country Gender COU_DEST Destination Country  Immigrant Stock  Immigrant Stock Imputed  Immigant Stock Missing Indicator  Origin Country Population  Destination Country Population\n",
            "1008  2000.0      AFG    Afghanistan    WMN      HUN             Hungary              NaN                     14.0                                 1                 20779957.0                      10210971.0\n",
            "1009  2001.0      AFG    Afghanistan    WMN      HUN             Hungary              NaN                     40.0                                 1                 21606992.0                      10187576.0\n",
            "1010  2002.0      AFG    Afghanistan    WMN      HUN             Hungary              NaN                     66.0                                 1                 22600774.0                      10158608.0\n",
            "1011  2003.0      AFG    Afghanistan    WMN      HUN             Hungary              NaN                     93.0                                 1                 23680871.0                      10129552.0\n",
            "1012  2004.0      AFG    Afghanistan    WMN      HUN             Hungary              NaN                    119.0                                 1                 24726689.0                      10107146.0\n",
            "1013  2005.0      AFG    Afghanistan    WMN      HUN             Hungary              NaN                    145.0                                 1                 25654274.0                      10087065.0\n",
            "1014  2006.0      AFG    Afghanistan    WMN      HUN             Hungary              NaN                    172.0                                 1                 26433058.0                      10071370.0\n",
            "1015  2007.0      AFG    Afghanistan    WMN      HUN             Hungary            236.0                    236.0                                 0                 27100542.0                      10055780.0\n",
            "1016  2008.0      AFG    Afghanistan    WMN      HUN             Hungary            243.0                    243.0                                 0                 27722281.0                      10038188.0\n",
            "1017  2009.0      AFG    Afghanistan    WMN      HUN             Hungary            257.0                    257.0                                 0                 28394806.0                      10022650.0\n",
            "1018  2010.0      AFG    Afghanistan    WMN      HUN             Hungary            266.0                    266.0                                 0                 29185511.0                      10000023.0\n",
            "1019  2011.0      AFG    Afghanistan    WMN      HUN             Hungary            271.0                    271.0                                 0                 30117411.0                       9971727.0\n",
            "1020  2012.0      AFG    Afghanistan    WMN      HUN             Hungary            289.0                    289.0                                 0                 31161378.0                       9920362.0\n",
            "1021  2013.0      AFG    Afghanistan    WMN      HUN             Hungary            350.0                    350.0                                 0                 32269592.0                       9893082.0\n",
            "1022  2014.0      AFG    Afghanistan    WMN      HUN             Hungary            397.0                    397.0                                 0                 33370804.0                       9866468.0\n",
            "1023  2015.0      AFG    Afghanistan    WMN      HUN             Hungary            403.0                    403.0                                 0                 34413603.0                       9843028.0\n",
            "1024  2016.0      AFG    Afghanistan    WMN      HUN             Hungary            415.0                    415.0                                 0                 35383028.0                       9814023.0\n",
            "1025  2017.0      AFG    Afghanistan    WMN      HUN             Hungary            414.0                    414.0                                 0                 36296111.0                       9787966.0\n",
            "1026  2018.0      AFG    Afghanistan    WMN      HUN             Hungary            543.0                    543.0                                 0                 37171922.0                       9775564.0\n",
            "1027  2019.0      AFG    Afghanistan    WMN      HUN             Hungary            540.0                    540.0                                 0                 38041757.0                       9771141.0\n",
            "1028  2020.0      AFG    Afghanistan    WMN      HUN             Hungary            548.0                    548.0                                 0                 38928341.0                       9749763.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can observe that the iterative imputer picks up the general data trend, however due to the large variation in data - it may predict even negative values. The negative values do not make sense from a business domain perspective, so the associated data should be set to 0. "
      ],
      "metadata": {
        "id": "jZJKTM26bbou"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.4 Putting it all together"
      ],
      "metadata": {
        "id": "u0AwgWnI5fXG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will consider the following data immputation strategy in regards with the **Immigrant Stock** feature:\n",
        "\n",
        "*  For any combination of (\"COU_ORIG\", \"COU_DEST\", \"Gender\") where there are less than 40% percent of missing records, the missing values will be imputed using the **Year** and **Immigrant Stock** features;\n",
        "*  If the iterative imputer generates negative imputation values, they will be set to 0;\n",
        "*  All other missing data will be set to 0.\n",
        "\n",
        "An implementation of this strategy can be found below, reusing the imputer from the previous example:"
      ],
      "metadata": {
        "id": "FpnF3vQw5-hg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reset the imputed values\n",
        "basic_valid_data[\"Immigrant Stock Imputed\"] = np.nan\n",
        "\n",
        "# imputing will be performed for all combination of \n",
        "# (\"COU_ORIG\", \"COU_DEST\", \"Gender\") selected for imputing\n",
        "for missing_value_combination in missing_value_combinations_imputation.values:\n",
        "\n",
        "  # extract relevant data\n",
        "  country_origin = missing_value_combination[0]\n",
        "  country_destination = missing_value_combination[1]\n",
        "  gender = missing_value_combination[2]\n",
        "\n",
        "  # slice from full data for the \n",
        "  # combination selected for imputing\n",
        "  slice_for_imputation = basic_valid_data[\n",
        "    (basic_valid_data[\"COU_ORIG\"] == country_origin)\n",
        "    &\n",
        "    (basic_valid_data[\"COU_DEST\"] == country_destination)\n",
        "    &\n",
        "    (basic_valid_data[\"Gender\"] == gender)\n",
        "  ]\n",
        "\n",
        "  # we will consider both \"Year\" and \"Immigrant Stock\" for imputation\n",
        "  values_to_transform = slice_for_imputation[[\"Year\", \"Immigrant Stock\"]].values\n",
        "\n",
        "  # fit and transform values for imputation\n",
        "  transformed_values = iterative_imputer.fit_transform(values_to_transform)\n",
        "\n",
        "  # extract in a meaningful way the transformed values\n",
        "  # make sure they represent an integer\n",
        "  transformed_values = transformed_values\n",
        "  transformed_values = transformed_values.astype(np.int32)\n",
        "\n",
        "  # set the imputer values back in the full data frame\n",
        "  basic_valid_data.loc[slice_for_imputation.index, \"Immigrant Stock Imputed\"] = transformed_values[:, 1]"
      ],
      "metadata": {
        "id": "zbT4clbw7Ofi"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display statistics about imputation results\n",
        "count_total_imputed = basic_valid_data[~np.isnan(basic_valid_data[\"Immigrant Stock Imputed\"])].shape[0]\n",
        "count_negatively_imputed = basic_valid_data[basic_valid_data[\"Immigrant Stock Imputed\"] < 0].shape[0]\n",
        "\n",
        "print (\n",
        "    \"The total values imputed are {}, out of which {} are imputed with negative values\".format(\n",
        "        count_total_imputed,\n",
        "        count_negatively_imputed\n",
        "    )\n",
        ")\n",
        "\n",
        "# set negatively imputed values to 0\n",
        "basic_valid_data.loc [(basic_valid_data[\"Immigrant Stock Imputed\"] < 0), \"Immigrant Stock Imputed\"] = 0 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPXV12oY-06f",
        "outputId": "1f3cab58-6311-43e7-fbca-d3a9d74b081f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The total values imputed are 50043, out of which 1745 are imputed with negative values\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# obtain count of values not imputed \n",
        "count_not_imputed = basic_valid_data[\n",
        "                                      (basic_valid_data[\"Immigant Stock Missing Indicator\"] == 1)\n",
        "                                      &\n",
        "                                      np.isnan(basic_valid_data[\"Immigrant Stock Imputed\"])\n",
        "                                    ].shape[0]\n",
        "\n",
        "print (\n",
        "    \"The total values not imputed yet are {}\".format(\n",
        "        count_not_imputed\n",
        "    )\n",
        ")\n",
        "\n",
        "# impute missing all the missing values to 0\n",
        "basic_valid_data.loc [\n",
        "                      (basic_valid_data[\"Immigant Stock Missing Indicator\"] == 1)\n",
        "                      &\n",
        "                      np.isnan(basic_valid_data[\"Immigrant Stock Imputed\"])\n",
        ", \"Immigrant Stock Imputed\"] = 0 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdOZXjImAQ2H",
        "outputId": "1ff99938-4d25-4f27-e725-0972e1cf4613"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The total values not imputed yet are 150966\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save the processed data\n",
        "basic_valid_data.to_parquet(\"migration_dataset_imputed.parquet\")"
      ],
      "metadata": {
        "id": "1StStaHPotgn"
      },
      "execution_count": 32,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "001_Data_Imputation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}