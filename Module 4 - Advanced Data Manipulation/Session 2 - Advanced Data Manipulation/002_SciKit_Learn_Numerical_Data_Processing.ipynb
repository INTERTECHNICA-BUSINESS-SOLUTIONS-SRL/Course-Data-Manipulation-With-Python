{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDuU6OSWXKo4"
      },
      "source": [
        "![*INTERTECHNICA - SOLON EDUCATIONAL PROGRAMS - TECHNOLOGY LINE*](https://solon.intertechnica.com/assets/IntertechnicaSolonEducationalPrograms-TechnologyLine.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeBbVwSSXKo9"
      },
      "source": [
        "# Data Manipulation with Python - Advanced Data Manipulation - Numerical Data Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUhqqWdPXKpA"
      },
      "source": [
        "*Basic initialization of the workspace.*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install numpy\n",
        "import numpy as np\n",
        "print (\"NumPy installed at version: {}\".format(np.__version__))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJzCFKioH6UR",
        "outputId": "3d9015d2-e92c-4403-9280-46a331f57e1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "NumPy installed at version: 1.19.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjAZRU7GXKpE",
        "outputId": "412cbe62-b033-452e-f4dc-d7040427c420",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Pandas installed at version: 1.3.5\n"
          ]
        }
      ],
      "source": [
        "!python -m pip install pandas\n",
        "import pandas as pd\n",
        "print (\"Pandas installed at version: {}\".format(pd.__version__))\n",
        "\n",
        "#adjust pandas DataFrame display for a wider target \n",
        "pd.set_option('display.expand_frame_repr', False)\n",
        "\n",
        "# disable warnings for chained assignment\n",
        "pd.set_option('mode.chained_assignment', None)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install sklearn\n",
        "import sklearn as skl\n",
        "import sklearn.preprocessing as sklp\n",
        "\n",
        "print (\"Sklearn installed at version: {}\".format(skl.__version__))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbyxoZM02V84",
        "outputId": "64f0482b-da1a-4bc3-a00a-52d3c01ce6ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.19.5)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.1.0)\n",
            "Sklearn installed at version: 1.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "\n",
        "# supress RuntimeWarnings that are not relevant\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "iMF0sJ6rN8Fj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1 Loading Data"
      ],
      "metadata": {
        "id": "mPYkEjtYty65"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will focus on processing a dataset focused on immigration data. It contains the number of foreign born citizens in different countries, considering different genders in different years. \n",
        "\n",
        "The dataset's values for immigrant stock have been imputed - so no missing data is expected on this feature.\n"
      ],
      "metadata": {
        "id": "jCNn1Jk-t2gz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.1 Loading and exploring data"
      ],
      "metadata": {
        "id": "PrWXFgFiugmV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First of all, loading data and basic exploration of the dataset structure is required. "
      ],
      "metadata": {
        "id": "iQYKBLNHuZ6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load data for processing\n",
        "loaded_data = pd.read_parquet(\n",
        "    \"https://github.com/INTERTECHNICA-BUSINESS-SOLUTIONS-SRL/CourseDataManipulationWithPython/raw/main/Module%204%20-%20Advanced%20Data%20Manipulation/Session%202%20-%20Advanced%20Data%20Manipulation/data/migration_dataset_imputed.parquet\"\n",
        ")\n",
        "\n",
        "print(\n",
        "    \"A sample of of loaded data is \\n {}\".format(\n",
        "      loaded_data[0:10]  \n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "mQy9EwjetX3W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46b2d8b4-c5cf-47e7-8e71-8698f99697c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A sample of of loaded data is \n",
            "    Year Gender COU_ORIG Origin Country  Origin Country Population COU_DEST Destination Country  Destination Country Population  Immigrant Stock Processed  Immigrant Stock Imputed Indicator\n",
            "0  2000    MEN      AFG    Afghanistan                 20779957.0      AUS           Australia                      19153000.0                     6500.0                                  0\n",
            "1  2001    MEN      AFG    Afghanistan                 21606992.0      AUS           Australia                      19413000.0                     7410.0                                  0\n",
            "2  2002    MEN      AFG    Afghanistan                 22600774.0      AUS           Australia                      19651400.0                     8710.0                                  0\n",
            "3  2003    MEN      AFG    Afghanistan                 23680871.0      AUS           Australia                      19895400.0                     9260.0                                  0\n",
            "4  2004    MEN      AFG    Afghanistan                 24726689.0      AUS           Australia                      20127400.0                     9810.0                                  0\n",
            "5  2005    MEN      AFG    Afghanistan                 25654274.0      AUS           Australia                      20394800.0                    10600.0                                  0\n",
            "6  2006    MEN      AFG    Afghanistan                 26433058.0      AUS           Australia                      20697900.0                    12170.0                                  0\n",
            "7  2007    MEN      AFG    Afghanistan                 27100542.0      AUS           Australia                      20827600.0                    13280.0                                  0\n",
            "8  2008    MEN      AFG    Afghanistan                 27722281.0      AUS           Australia                      21249200.0                    14230.0                                  0\n",
            "9  2009    MEN      AFG    Afghanistan                 28394806.0      AUS           Australia                      21691700.0                    15360.0                                  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can observe that the dataset has several features:\n",
        "\n",
        "*  **Year** - the year of observation;\n",
        "*  **Gender** - the gender of the immigrants;\n",
        "*  **COU_ORIG** - the ISO3 code for the country of origin;\n",
        "*  **Origin Country** - the name of the country of origin (country of birth/nationality);\n",
        "*  **Origin Country Population** - the population in the country of origin;\n",
        "*  **COU_DEST** - the country of destination (country of residence);\n",
        "*  **Destination Country** - the country of residence;\n",
        "*  **Destination Country Population** - the population in the country of destination;\n",
        "*  **Immigrant Stock Processed** - the number of immigrants (foreign born citizens) which was processed by providing imputed values where the original data has been missing;\n",
        "*  **Immigrant Stock Imputed Indicator** - an indicator specifying if the immigrant stock value is the original one or it has been missing and the actual value is imputed.\n"
      ],
      "metadata": {
        "id": "hsNM6uGxuuND"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are interested in making sure that the numerical features are processed in a manner that is most useful both for data insights and for machine learning processing.\n",
        "\n",
        "First of all, let's find out some statistical information about these features:"
      ],
      "metadata": {
        "id": "QEpQqmRi9WuX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the target numerical values\n",
        "target_features = [\n",
        "                    \"Immigrant Stock Processed\",\n",
        "                    \"Origin Country Population\",\n",
        "                    \"Destination Country Population\"\n",
        "                  ]\n",
        "\n",
        "# print basic statistics about target features\n",
        "for target_feature in target_features :\n",
        "  target_feature_valid = loaded_data[~np.isnan(loaded_data[target_feature])]\n",
        "\n",
        "  print(\"Target feature: {} \\n\".format(target_feature))\n",
        "  print(\"Min Value: {:.2f}, Max Value: {:.2f}, Average Value: {:.2f}, Standard Deviation {:.2f} \\n\".format(\n",
        "      np.min(target_feature_valid[target_feature]),\n",
        "      np.max(target_feature_valid[target_feature]),\n",
        "      np.average(target_feature_valid[target_feature]),\n",
        "      np.std(target_feature_valid[target_feature])\n",
        "    )\n",
        "  )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaYOEZri9VBQ",
        "outputId": "3e561ae3-1ac8-470d-a218-75329f1fde2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target feature: Immigrant Stock Processed \n",
            "\n",
            "Min Value: 0.00, Max Value: 11714489.00, Average Value: 6853.38, Standard Deviation 88985.54 \n",
            "\n",
            "Target feature: Origin Country Population \n",
            "\n",
            "Min Value: 9392.00, Max Value: 1410929362.00, Average Value: 34891321.29, Standard Deviation 133379259.47 \n",
            "\n",
            "Target feature: Destination Country Population \n",
            "\n",
            "Min Value: 281205.00, Max Value: 329484123.00, Average Value: 32103057.69, Standard Deviation 56298756.97 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.2 Feature scaling"
      ],
      "metadata": {
        "id": "haJFHoogxakm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can observe that there is a lot of variability in the numerical features. \n",
        "\n",
        "Usually, for many machine learning algorithms, a high variability in the data along with a wide interval of values are highly detrimental for algorithmic performance. In many cases, the data should be processed so that it is fit into a clearly defined interval (usually [0,1])."
      ],
      "metadata": {
        "id": "2K2Z2vMuwF4K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The sklearn library has a strong support for data scaling via the [**MinMaxScaler**](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler) or the [**RobustScaler**](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html#sklearn.preprocessing.RobustScaler) classes.\n",
        "\n",
        "In case the data variability is high, the RobustScaler class is preffered since it is quite resilient to data outliers (data that have extreme or unusual values)."
      ],
      "metadata": {
        "id": "YMRwAq7ormZv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In case of the **Origin Country Population** and **Destination Country Population** we can scale the features at the country (origin or destination) level. We would like to keep the values in the interval [0,1] and this is done by using the MinMaxScaler for each slice of data associated with an origin or destination country. "
      ],
      "metadata": {
        "id": "Ixmwwuu6tKb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a column for origin and destination country population\n",
        "# scaled values\n",
        "loaded_data[\"Origin Country Population Scaled\"] = np.nan\n",
        "loaded_data[\"Destination Country Population Scaled\"] = np.nan\n",
        "\n",
        "# process all origin countries\n",
        "origin_countries = loaded_data[\"COU_ORIG\"]\n",
        "origin_countries = origin_countries.drop_duplicates()\n",
        "\n",
        "for origin_country in origin_countries.values :\n",
        "  # determine the slice of data for the origin country\n",
        "  origin_country_slice = loaded_data[loaded_data[\"COU_ORIG\"] == origin_country]\n",
        "\n",
        "  # scale the data and assign it to the corresponding feature\n",
        "  origin_country_scaler = sklp.MinMaxScaler()\n",
        "  loaded_data.loc[origin_country_slice.index, \"Origin Country Population Scaled\"] = \\\n",
        "    origin_country_scaler.fit_transform(\n",
        "        origin_country_slice[\"Origin Country Population\"].values.reshape((-1,1)) \n",
        "      )\n",
        "\n",
        "# we process the destination countries as well\n",
        "destination_countries = loaded_data[\"COU_DEST\"]\n",
        "destination_countries = destination_countries.drop_duplicates()\n",
        "\n",
        "for destination_country in destination_countries.values :\n",
        "  # slice the data for a specific destination country\n",
        "  destination_country_slice = loaded_data[loaded_data[\"COU_DEST\"] == destination_country]\n",
        "\n",
        "  # scale the data and assign it to the corresponding feature\n",
        "  destination_country_scaler = sklp.MinMaxScaler()\n",
        "  loaded_data.loc[destination_country_slice.index, \"Destination Country Population Scaled\"] = \\\n",
        "    destination_country_scaler.fit_transform(\n",
        "        destination_country_slice[\"Destination Country Population\"].values.reshape((-1,1)) \n",
        "      )"
      ],
      "metadata": {
        "id": "-ane2XOQts8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will scale the **Immigrant Stock Processed** feature as well, this time over all the applicable (Origin Country, Destination Country) combinations."
      ],
      "metadata": {
        "id": "2IGoe_16Rdh8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get all the applicable (origin country, destination country) combinations\n",
        "country_combinations = loaded_data[[\"COU_ORIG\", \"COU_DEST\"]]\n",
        "country_combinations = country_combinations.drop_duplicates()\n",
        "\n",
        "# create a column for scaled values of Immigrant Stock Processed feature\n",
        "loaded_data[\"Immigrant Stock Processed Scaled\"] = np.nan\n",
        "\n",
        "for origin_country, destination_country in country_combinations.values:\n",
        "  # determine the slice of data for the origin and destination country\n",
        "  data_slice = loaded_data[loaded_data[\"COU_ORIG\"] == origin_country]\n",
        "  data_slice = data_slice[data_slice[\"COU_DEST\"] == destination_country]\n",
        "\n",
        "  # scale the data and assign it to the corresponding feature\n",
        "  immigrant_stock_scaler = sklp.MinMaxScaler()\n",
        "  loaded_data.loc[data_slice.index, \"Immigrant Stock Processed Scaled\"] = \\\n",
        "      immigrant_stock_scaler.fit_transform(\n",
        "        data_slice[\"Immigrant Stock Processed\"].values.reshape((-1,1))\n",
        "      )"
      ],
      "metadata": {
        "id": "WDWG4niMRvYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display a data sample\n",
        "print(\n",
        "    \"A sample of the scaled data is as follows \\n{}\".format(\n",
        "        loaded_data[0:10]\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6imDfqNdNYNT",
        "outputId": "198c99eb-beda-4163-d1f6-bf523bac81af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A sample of the scaled data is as follows \n",
            "   Year Gender COU_ORIG Origin Country  Origin Country Population COU_DEST Destination Country  Destination Country Population  Immigrant Stock Processed  Immigrant Stock Imputed Indicator  Origin Country Population Scaled  Destination Country Population Scaled  Immigrant Stock Processed Scaled\n",
            "0  2000    MEN      AFG    Afghanistan                 20779957.0      AUS           Australia                      19153000.0                     6500.0                                  0                          0.000000                               0.000000                          0.055057\n",
            "1  2001    MEN      AFG    Afghanistan                 21606992.0      AUS           Australia                      19413000.0                     7410.0                                  0                          0.045571                               0.039792                          0.082286\n",
            "2  2002    MEN      AFG    Afghanistan                 22600774.0      AUS           Australia                      19651400.0                     8710.0                                  0                          0.100329                               0.076277                          0.121185\n",
            "3  2003    MEN      AFG    Afghanistan                 23680871.0      AUS           Australia                      19895400.0                     9260.0                                  0                          0.159844                               0.113620                          0.137642\n",
            "4  2004    MEN      AFG    Afghanistan                 24726689.0      AUS           Australia                      20127400.0                     9810.0                                  0                          0.217470                               0.149127                          0.154099\n",
            "5  2005    MEN      AFG    Afghanistan                 25654274.0      AUS           Australia                      20394800.0                    10600.0                                  0                          0.268581                               0.190051                          0.177738\n",
            "6  2006    MEN      AFG    Afghanistan                 26433058.0      AUS           Australia                      20697900.0                    12170.0                                  0                          0.311493                               0.236439                          0.224716\n",
            "7  2007    MEN      AFG    Afghanistan                 27100542.0      AUS           Australia                      20827600.0                    13280.0                                  0                          0.348273                               0.256289                          0.257929\n",
            "8  2008    MEN      AFG    Afghanistan                 27722281.0      AUS           Australia                      21249200.0                    14230.0                                  0                          0.382531                               0.320812                          0.286355\n",
            "9  2009    MEN      AFG    Afghanistan                 28394806.0      AUS           Australia                      21691700.0                    15360.0                                  0                          0.419588                               0.388534                          0.320168\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the target numerical values\n",
        "target_features = [\n",
        "                    \"Immigrant Stock Processed Scaled\",\n",
        "                    \"Origin Country Population Scaled\",\n",
        "                    \"Destination Country Population Scaled\"\n",
        "                  ]\n",
        "\n",
        "# print basic statistics about target features\n",
        "for target_feature in target_features :\n",
        "  target_feature_valid = loaded_data[~np.isnan(loaded_data[target_feature])]\n",
        "\n",
        "  print(\"Target feature: {} \\n\".format(target_feature))\n",
        "  print(\"Min Value: {:.2f}, Max Value: {:.2f}, Average Value: {:.2f}, Standard Deviation {:.2f} \\n\".format(\n",
        "      np.min(target_feature_valid[target_feature]),\n",
        "      np.max(target_feature_valid[target_feature]),\n",
        "      np.average(target_feature_valid[target_feature]),\n",
        "      np.std(target_feature_valid[target_feature])\n",
        "    )\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0Ahc_9uWCoV",
        "outputId": "1c377eff-9c99-45de-8f7c-9dd6f40d2974"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target feature: Immigrant Stock Processed Scaled \n",
            "\n",
            "Min Value: 0.00, Max Value: 1.00, Average Value: 0.21, Standard Deviation 0.32 \n",
            "\n",
            "Target feature: Origin Country Population Scaled \n",
            "\n",
            "Min Value: 0.00, Max Value: 1.00, Average Value: 0.48, Standard Deviation 0.32 \n",
            "\n",
            "Target feature: Destination Country Population Scaled \n",
            "\n",
            "Min Value: 0.00, Max Value: 1.00, Average Value: 0.48, Standard Deviation 0.32 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A this point we decide to address only the combination that has a ratio of missing records of 0.4 or less. This is an empirical decision, ratio can vary depending on the data analyst and business needs.\n",
        "\n",
        "Therefore we will leave all the combinations having a ratio of more than 0.4 as is, for the rest we will used data imputation in order to replace missing values with estimated ones.  "
      ],
      "metadata": {
        "id": "WTzziYA905iI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the final processed data\n",
        "# retaining only the relevant information\n",
        "final_data = loaded_data[[\n",
        "                                \"Year\", \n",
        "                                \"Gender\", \n",
        "                                \"COU_ORIG\", \n",
        "                                \"Origin Country\",\n",
        "                                \"Origin Country Population\",\n",
        "                                \"Origin Country Population Scaled\",\n",
        "                                \"COU_DEST\",\n",
        "                                \"Destination Country\",\n",
        "                                \"Destination Country Population\",\n",
        "                                \"Destination Country Population Scaled\",\n",
        "                                \"Immigrant Stock Processed\",\n",
        "                                \"Immigrant Stock Processed Scaled\",\n",
        "                                \"Immigrant Stock Imputed Indicator\"\n",
        "                               ]]\n",
        "\n",
        "# make sure the year remains an integer value\n",
        "final_data[\"Year\"] = final_data[\"Year\"].astype(\"int16\")"
      ],
      "metadata": {
        "id": "TCIkA914zK-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display a sample of the final data\n",
        "print(\n",
        "    \"A sample of final processed data is \\n {}\".format(\n",
        "      final_data[0:10]  \n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlLAKP8T4qr1",
        "outputId": "e97ce3c0-4771-40b6-abb7-f7b50bb8da6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A sample of final processed data is \n",
            "    Year Gender COU_ORIG Origin Country  Origin Country Population  Origin Country Population Scaled COU_DEST Destination Country  Destination Country Population  Destination Country Population Scaled  Immigrant Stock Processed  Immigrant Stock Processed Scaled  Immigrant Stock Imputed Indicator\n",
            "0  2000    MEN      AFG    Afghanistan                 20779957.0                          0.000000      AUS           Australia                      19153000.0                               0.000000                     6500.0                          0.055057                                  0\n",
            "1  2001    MEN      AFG    Afghanistan                 21606992.0                          0.045571      AUS           Australia                      19413000.0                               0.039792                     7410.0                          0.082286                                  0\n",
            "2  2002    MEN      AFG    Afghanistan                 22600774.0                          0.100329      AUS           Australia                      19651400.0                               0.076277                     8710.0                          0.121185                                  0\n",
            "3  2003    MEN      AFG    Afghanistan                 23680871.0                          0.159844      AUS           Australia                      19895400.0                               0.113620                     9260.0                          0.137642                                  0\n",
            "4  2004    MEN      AFG    Afghanistan                 24726689.0                          0.217470      AUS           Australia                      20127400.0                               0.149127                     9810.0                          0.154099                                  0\n",
            "5  2005    MEN      AFG    Afghanistan                 25654274.0                          0.268581      AUS           Australia                      20394800.0                               0.190051                    10600.0                          0.177738                                  0\n",
            "6  2006    MEN      AFG    Afghanistan                 26433058.0                          0.311493      AUS           Australia                      20697900.0                               0.236439                    12170.0                          0.224716                                  0\n",
            "7  2007    MEN      AFG    Afghanistan                 27100542.0                          0.348273      AUS           Australia                      20827600.0                               0.256289                    13280.0                          0.257929                                  0\n",
            "8  2008    MEN      AFG    Afghanistan                 27722281.0                          0.382531      AUS           Australia                      21249200.0                               0.320812                    14230.0                          0.286355                                  0\n",
            "9  2009    MEN      AFG    Afghanistan                 28394806.0                          0.419588      AUS           Australia                      21691700.0                               0.388534                    15360.0                          0.320168                                  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save the processed data\n",
        "final_data.to_parquet(\"migration_dataset_numerically_processed.parquet\")"
      ],
      "metadata": {
        "id": "1StStaHPotgn"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "002_SciKit_Learn_Numerical_Data_Processing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}